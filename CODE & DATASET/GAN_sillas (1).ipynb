{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2906145,"sourceType":"datasetVersion","datasetId":1781167}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["<span style=\"font-family:Papyrus; font-size:2.5em;\">Generative Adversarial Network (GAN) para sillas</span>\n","---\n","![](https://espresso-jobs.com/conseils-carriere/wp-content/uploads/2019/05/monalisa.gif)\n","<br>"],"metadata":{"id":"YoWtC9uJ-6hX"}},{"cell_type":"markdown","source":["# Preparativos\n","\n","\n","\n"],"metadata":{"id":"PZrwRYuV-6hb"}},{"cell_type":"markdown","source":["**Conectamos drive**"],"metadata":{"id":"HuV7mIce-6ha"}},{"cell_type":"code","source":["#Si trabajamos con carpeta local de drive, primero conectamos\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"t1ZGWrty0ZjO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Importamos bibliotecas**"],"metadata":{"id":"xna816rw-6hc"}},{"cell_type":"code","source":["from __future__ import print_function\n","from time import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch import nn, optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","from tqdm.notebook import tqdm\n","import os\n","from torch.autograd import Variable\n","\n","print('librerías importadas')"],"metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-06-10T10:39:29.726590Z","iopub.execute_input":"2025-06-10T10:39:29.726933Z","iopub.status.idle":"2025-06-10T10:39:40.647074Z","shell.execute_reply.started":"2025-06-10T10:39:29.726906Z","shell.execute_reply":"2025-06-10T10:39:40.646025Z"},"trusted":true,"id":"7smt7gMN-6hd"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# NO ejecutar en colab. Solo si trabajamos con kaggle para ver inputs disponibles\n","!ls /kaggle/input"],"metadata":{"execution":{"iopub.status.busy":"2025-06-10T10:39:44.221440Z","iopub.execute_input":"2025-06-10T10:39:44.221851Z","iopub.status.idle":"2025-06-10T10:39:44.358227Z","shell.execute_reply.started":"2025-06-10T10:39:44.221822Z","shell.execute_reply":"2025-06-10T10:39:44.357129Z"},"trusted":true,"id":"5yMb2Sh2-6hf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["**Definimos rutas y comprobamos dataset**"],"metadata":{"id":"l9T3T_eCFtCr"}},{"cell_type":"code","source":["# Descomentar rutas para dataset original si trabajamos con Kaggle\n","# FOLDER = '/kaggle/input/'\n","# CLASS = 'antic-chairs/antic_chairs/'\n","# PATH =  '/kaggle/input/antic-chairs/antic_chairs/'\n","\n","# Descomentar rutas para dataset original si trabajamos con Colab\n","# FOLDER = '/content/drive/MyDrive/ColabNotebooks/datasets/'\n","# CLASS = 'chairs/antic_chairs/'\n","# PATH = '/content/drive/MyDrive/ColabNotebooks/datasets/chairs/antic_chairs/'\n","\n","# rutas para datset activo\n","FOLDER = '/content/drive/MyDrive/ColabNotebooks/dataset3/'\n","CLASS = 'sillas/sillas_100ext_aum/'\n","PATH = '/content/drive/MyDrive/ColabNotebooks/dataset3/sillas/sillas_100ext_aum/'\n","\n","BASE_SAVE_PATH = '/content/drive/MyDrive/ColabNotebooks/results/'\n","TEST_SAVE_PATH = '/content/drive/MyDrive/ColabNotebooks/test_generated_images/'\n","\n","\n","# hcermos recuento delvnúmero de imágenes en dataset\n","images = os.listdir(PATH)\n","print(f'There are {len(os.listdir(PATH))} chairs .')\n","\n","fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12,10))\n","\n","for indx, axis in enumerate(axes.flatten()):\n","    rnd_indx = np.random.randint(0, len(os.listdir(PATH)))\n","    # https://matplotlib.org/users/image_tutorial.html\n","    img = plt.imread(PATH + images[rnd_indx])\n","    imgplot = axis.imshow(img)\n","    axis.set_title(images[rnd_indx])\n","    axis.set_axis_off()\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","\n","print('Maximo: ', np.max(img), 'Minimo: ', np.min(img))"],"metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2025-06-10T10:39:48.550350Z","iopub.execute_input":"2025-06-10T10:39:48.550702Z","iopub.status.idle":"2025-06-10T10:39:49.891323Z","shell.execute_reply.started":"2025-06-10T10:39:48.550669Z","shell.execute_reply":"2025-06-10T10:39:49.890123Z"},"trusted":true,"id":"UhQekJQz-6hf"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["**Seleccionamos cuda o cpu**"],"metadata":{"id":"hMV9LXo1-6hg"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"execution":{"iopub.status.busy":"2025-06-10T10:39:56.366765Z","iopub.execute_input":"2025-06-10T10:39:56.367141Z","iopub.status.idle":"2025-06-10T10:39:56.376021Z","shell.execute_reply.started":"2025-06-10T10:39:56.367111Z","shell.execute_reply":"2025-06-10T10:39:56.374735Z"},"trusted":true,"id":"O_cMjjIn-6hj"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Preparación de imágenes\n"],"metadata":{"id":"vxIywcQnIw4u"}},{"cell_type":"markdown","source":["**Transformación de imágenes del dataset y dataloader**"],"metadata":{"id":"aHRztndpGTGV"}},{"cell_type":"code","source":["batch_size = 32 # número de imgs de cada lote\n","image_size = 64 #dimensiones de las imágenes\n","latent_dim = 100 # dimensionalidad del vector de ruido\n","\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# algoritmo de transformación de imgs con normalización\n","transform = transforms.Compose([transforms.Resize(64),\n","                                transforms.CenterCrop(64),\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","# algoritmo de transformación de imgs sin normalización\n","transform_noresize = transforms.Compose([transforms.Resize(64),\n","                                        #transforms.CenterCrop(64),\n","                                         transforms.ToTensor()])\n","\n","# Definimos cargador 1 de imágenes para entrenamiento\n","train_data = datasets.ImageFolder(FOLDER, transform=transform)\n","train_loader = DataLoader(train_data, shuffle=True,\n","                                           batch_size=batch_size)\n","\n","# Definimos cargador 2 de imágenes para entrenamiento\n","train_data_noresize = datasets.ImageFolder(FOLDER, transform=transform_noresize)\n","train_loader_noresize = DataLoader(train_data_noresize, shuffle=True,\n","                                           batch_size=batch_size)"],"metadata":{"execution":{"iopub.status.busy":"2025-06-10T10:40:10.116066Z","iopub.execute_input":"2025-06-10T10:40:10.116408Z","iopub.status.idle":"2025-06-10T10:40:10.900661Z","shell.execute_reply.started":"2025-06-10T10:40:10.116386Z","shell.execute_reply":"2025-06-10T10:40:10.899078Z"},"trusted":true,"id":"i23nGh9S-6hk"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["**Comprobamos los train_loader del dataset**"],"metadata":{"id":"8K3LlCgHIJoW"}},{"cell_type":"code","source":["# Definimos imágenes con cada train_loader\n","imgs, label = next(iter(train_loader))\n","imgs = imgs.numpy().transpose(0, 2, 3, 1)\n","\n","imgs_noresize, label_noresize = next(iter(train_loader_noresize))\n","imgs_noresize = imgs_noresize.numpy().transpose(0, 2, 3, 1)\n","\n","# Mostramos por pantalla las imágenes de ambos cargadores\n","print(imgs.shape)\n","for i in range(5):\n","    plt.imshow(imgs[i])\n","    plt.show()\n","\n","print(imgs_noresize.shape)\n","for i in range(5):\n","    plt.imshow(imgs_noresize[i])\n","    plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2025-06-10T10:40:16.558966Z","iopub.execute_input":"2025-06-10T10:40:16.559301Z","iopub.status.idle":"2025-06-10T10:40:18.334970Z","shell.execute_reply.started":"2025-06-10T10:40:16.559276Z","shell.execute_reply":"2025-06-10T10:40:18.334047Z"},"trusted":true,"id":"rEiDBFuM-6hk"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Definimos pesos iniciales\n"],"metadata":{"id":"PXiwbibu-6hl"}},{"cell_type":"code","source":["def weights_init(m):\n","    \"\"\"\n","    Takes as input a neural network m that will initialize all its weights.\n","    \"\"\"\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        m.weight.data.normal_(0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        m.weight.data.normal_(1.0, 0.02)\n","        m.bias.data.fill_(0)"],"metadata":{"execution":{"iopub.status.busy":"2025-06-10T10:40:24.506385Z","iopub.execute_input":"2025-06-10T10:40:24.506707Z","iopub.status.idle":"2025-06-10T10:40:24.513233Z","shell.execute_reply.started":"2025-06-10T10:40:24.506683Z","shell.execute_reply":"2025-06-10T10:40:24.512263Z"},"trusted":true,"id":"j--eCHbe-6hl"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Generadores"],"metadata":{"id":"O_7QdeGq-6hm"}},{"cell_type":"markdown","source":["Ejecutamos uno de los 3 siguientes Generadores"],"metadata":{"id":"0l4AlDelzk91"}},{"cell_type":"code","source":["# GENERADOR 1 (generador inicial)\n","\n","class G(nn.Module):\n","    def __init__(self):\n","\n","        super(G, self).__init__()\n","\n","        self.main = nn.Sequential(  # Definimos secuencia de módulos (capas, operaciones)\n","                nn.ConvTranspose2d(latent_dim, 512, 4, stride=2, padding=0, bias=False),\n","                nn.BatchNorm2d(512),\n","                nn.ReLU(True),\n","                nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False),\n","                nn.BatchNorm2d(256),\n","                nn.ReLU(True),\n","                nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n","                nn.BatchNorm2d(128),\n","                nn.ReLU(True),\n","                nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False),\n","                nn.BatchNorm2d(64),\n","                nn.ReLU(True),\n","                nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1, bias=False),\n","                nn.Sigmoid()\n","                )\n","\n","# Definimos flujo de datos\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output\n","\n","# Definimos Generador\n","netG = G().to(device)\n","netG.apply(weights_init)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:40:35.589384Z","iopub.execute_input":"2025-06-10T10:40:35.589724Z","iopub.status.idle":"2025-06-10T10:40:35.670812Z","shell.execute_reply.started":"2025-06-10T10:40:35.589683Z","shell.execute_reply":"2025-06-10T10:40:35.669657Z"},"id":"tMQdiIO2-6hn"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# GENERADOR 2 CON NÚMERO DE FILTROS CONFIGURABLE\n","\n","latent_dim = 100 # dimensión de vector ruido de entrada\n","ngf = 128 # factor de número de filtros para bloques deconv\n","\n","class G(nn.Module):\n","    def __init__(self):\n","        super(G, self).__init__()\n","        self.main = nn.Sequential(  # Definimos secuencia de módulos (capas, operaciones)\n","\n","            #1 (desde vector de ruido)\n","            # Input: (batch_size, latent_dim, 1, 1)\n","            nn.ConvTranspose2d(latent_dim, ngf * 8, 4, stride=1, padding=0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf * 8, 4, 4)\n","\n","            #2\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf * 4, 8, 8)\n","\n","            #3\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf * 2, 16, 16)\n","\n","            #4\n","            nn.ConvTranspose2d(ngf * 2, ngf, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf, 32, 32)\n","\n","            #5 (Final layer for 64x64 output)\n","            nn.ConvTranspose2d(ngf, 3, 4, stride=2, padding=1, bias=False),\n","            nn.Sigmoid()\n","            # Output: (batch_size, 3, 64, 64)\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","\n","\n","# Definimos flujo de datos\n","    def forward(self, input):\n","        output = self.main(input)\n","        return output\n","\n","# Definimos Generador\n","netG = G().to(device)\n","netG.apply(weights_init)"],"metadata":{"trusted":true,"id":"C1qMKk4V-6ho"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# GENERADOR 3 (6 BLOQUES DECONVOLUCIONALES)\n","\n","latent_dim = 100 # dimensión de vector ruido de entrada\n","\n","ngf = 64 # factor de número de filtros para bloques deconv\n","\n","class G(nn.Module):\n","    def __init__(self):\n","        super(G, self).__init__()\n","        self.main = nn.Sequential( # Definimos secuencia de módulos (capas, operaciones)\n","\n","            # 1: latent_dim -> 4x4 (ngf*16 filtros, canales)\n","            # Input: (batch_size, latent_dim, 1, 1)\n","            nn.ConvTranspose2d(latent_dim, ngf * 16, 4, stride=1, padding=0, bias=False),\n","            nn.BatchNorm2d(ngf * 16),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf * 16, 4, 4)\n","\n","            # 2: 4x4 -> 8x8 (ngf*8 filtros, canales)\n","            nn.ConvTranspose2d(ngf * 16, ngf * 8, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf * 8, 8, 8)\n","\n","            # 3: 8x8 -> 16x16 (ngf*4 filtros, canales)\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf * 4, 16, 16)\n","\n","            # 4: 16x16 -> 32x32 (ngf*2 filtros, canales)\n","            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf * 2, 32, 32)\n","\n","            # 5: 32x32 -> 64x64 (ngf canales) --- Esta capa alcanza la dimensión de imagen deseada (64 x 64)\n","            nn.ConvTranspose2d(ngf * 2, ngf, 4, stride=2, padding=1, bias=False), # (32-1)*2 - 2*1 + 4 = 62-2+4 = 64\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            # Output: (batch_size, ngf, 64, 64)\n","\n","            # 6: 64x64 -> 64x64 RGB (3 canales) --- Esta capa modifica el número de canales pero no dimensión del mapa\n","            nn.ConvTranspose2d(ngf, 3, 1, stride=1, padding=0, bias=False), # kernel_size=1, stride=1, padding=0 is like 1x1 conv\n","            nn.Sigmoid()\n","\n","            # Output: (batch_size, 3, 64, 64)\n","        )\n","\n","# Definimos flujo de datos\n","   # def forward(self, input):\n","       # return self.main(input)\n","def forward(self, input):\n","        output = self.main(input)\n","        return output\n","\n","# Creamos Generador\n","netG = G().to(device)\n","netG.apply(weights_init)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T10:41:39.032966Z","iopub.execute_input":"2025-06-10T10:41:39.033323Z","iopub.status.idle":"2025-06-10T10:41:39.388540Z","shell.execute_reply.started":"2025-06-10T10:41:39.033299Z","shell.execute_reply":"2025-06-10T10:41:39.387097Z"},"id":"ZwUGg51P-6hp"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Discriminador"],"metadata":{"id":"6rjxu0_f-6hp"}},{"cell_type":"code","source":["\n","class D(nn.Module):\n","    def __init__(self):\n","        super(D, self).__init__()\n","        self.main = nn.Sequential( # Definimos secuencia de módulos (capas, operaciones)\n","\n","                # 1\n","                nn.Conv2d(3, 64, 4, stride=1, padding=1, bias=False),\n","                nn.MaxPool2d(2,2),\n","                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","                nn.Dropout(0.3),\n","                # 2\n","                nn.Conv2d(64, 128, 4, stride=1, padding=1, bias=False),\n","                nn.MaxPool2d(2,2),\n","                nn.BatchNorm2d(128),\n","                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","                nn.Dropout(0.3),\n","                # 3\n","                nn.Conv2d(128, 256, 4, stride=1, padding=1, bias=False),\n","                nn.MaxPool2d(2,2),\n","                nn.BatchNorm2d(256),\n","                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","                nn.Dropout(0.3),\n","                # 4\n","                nn.Conv2d(256, 512, 4, stride=1, padding=1, bias=False),\n","                nn.MaxPool2d(2,2),\n","                nn.BatchNorm2d(512),\n","                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","                nn.Dropout(0.3),\n","\n","                nn.Flatten(),\n","\n","                # 5. Red densa\n","                nn.Linear(4608,100),\n","                nn.LeakyReLU(negative_slope=0.2, inplace=True),\n","                nn.Linear(100,1),\n","                nn.Sigmoid()\n","                )\n","\n","# Definimos flujo de datos\n","    def forward(self, input):\n","        output = self.main(input)\n","        # .view(-1) = Aplana salida a 1D en lugar de 2D\n","        return output.view(-1)\n","\n","\n","# Creamos el Discriminador\n","netD = D().to(device)\n","netD.apply(weights_init)\n"],"metadata":{"execution":{"iopub.status.busy":"2025-06-10T10:42:17.794464Z","iopub.execute_input":"2025-06-10T10:42:17.794768Z","iopub.status.idle":"2025-06-10T10:42:17.861446Z","shell.execute_reply.started":"2025-06-10T10:42:17.794745Z","shell.execute_reply":"2025-06-10T10:42:17.860646Z"},"trusted":true,"id":"6POjEZvU-6hp"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Entrenamiento"],"metadata":{"id":"inKLTcEa-6hp"}},{"cell_type":"code","source":["# NO ejecutar en colab\n","!mkdir results\n","!ls"],"metadata":{"execution":{"iopub.status.busy":"2025-06-10T10:42:43.659218Z","iopub.execute_input":"2025-06-10T10:42:43.659510Z","iopub.status.idle":"2025-06-10T10:42:43.934761Z","shell.execute_reply.started":"2025-06-10T10:42:43.659491Z","shell.execute_reply":"2025-06-10T10:42:43.933360Z"},"trusted":true,"id":"AzUtxivN-6hq"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["LR = 0.0002 # tasa de aprendizaje\n","\n","# tasas diferenciadas para G y D\n","LR_G = 0.0002\n","LR_D = 0.0002\n","\n","criterion = nn.BCELoss()\n","optimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(0.5, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(0.5, 0.999))\n"],"metadata":{"execution":{"iopub.status.busy":"2025-06-10T10:42:47.599370Z","iopub.execute_input":"2025-06-10T10:42:47.599747Z","iopub.status.idle":"2025-06-10T10:42:47.608403Z","shell.execute_reply.started":"2025-06-10T10:42:47.599717Z","shell.execute_reply":"2025-06-10T10:42:47.607176Z"},"trusted":true,"id":"MZl6DU9e-6hr"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["**Seleccionar y ejecutar uno de los 2 siguientes entrenamientos**"],"metadata":{"id":"M1Yb4M5dZ4CZ"}},{"cell_type":"code","source":["# ENTRENADOR 1 (una optimización de generador por cada una del discriminador, mismo vector de ruido)\n","\n","# Descomentar el data loader seleccionado:\n","# data_loader = train_loader\n","data_loader = train_loader_noresize\n","\n","EPOCH = 300 # número de épocas\n","\n","losses_D = []\n","losses_G = []\n","\n","t0 = time()\n","for epoch in range(EPOCH):\n","    epoch_loss_D = 0\n","    epoch_loss_G = 0\n","    num_batches = 0\n","    for i, data in enumerate(data_loader, 0):\n","\n","        # Actualizamos pesos d ela red del Discriminador\n","        netD.zero_grad()\n","\n","        # Entrenamos Dscriminador con lote de imágenes reales\n","        input,_ = data\n","        input = input.to(device)\n","        target = torch.ones(input.size()[0]).to(device)\n","        output = netD(input)\n","        errD_real = criterion(output, target)\n","\n","        # Entrenamos Discriminador con lote de imágenes falsas producidad por el Generador\n","        noise = torch.randn(input.size()[0], 100, 1, 1).to(device)\n","        fake = netG(noise)\n","        target = torch.zeros(input.size()[0]).to(device)\n","        output = netD(fake.detach())\n","        errD_fake = criterion(output, target)\n","\n","        # Sumamos errores y hacemos bacpropagation\n","        errD = errD_real + errD_fake\n","        errD.backward()\n","        optimizerD.step()\n","\n","        # Actualizamos (optimizamos) pesos del Generador\n","        netG.zero_grad()\n","        target = torch.ones(input.size()[0]).to(device)\n","        output = netD(fake)\n","        errG = criterion(output, target)\n","        errG.backward()\n","        optimizerG.step()\n","\n","        # Acumulamos errores\n","        epoch_loss_D += errD.item()\n","        epoch_loss_G += errG.item()\n","        num_batches += 1\n","\n","    losses_D.append(epoch_loss_D / num_batches)\n","    losses_G.append(epoch_loss_G / num_batches)\n","\n","    # Mostraos errores por pantalla y guardamos muestra de imágenes reales y otra de imñagenes generadas\n","    print('[%d/%d] Loss_D: %.4f; Loss_G: %.4f' % (epoch, EPOCH, errD.item(), errG.item()))\n","    save_image(input, os.path.join(BASE_SAVE_PATH, 'real_samples.png'), normalize=True)\n","    save_image(fake.data, os.path.join(BASE_SAVE_PATH, 'fake_samples_epoch_%03d.png' % epoch), normalize=True)\n","tf = time()\n","print(tf - t0)\n","\n","# Guardamos pesos de Generador y Discriminador\n","best_model_g = os.path.join(BASE_SAVE_PATH, 'generator_v2.pth')\n","best_model_d = os.path.join(BASE_SAVE_PATH, 'discriminator_v2.pth')\n","torch.save(netG.state_dict(), best_model_g)\n","torch.save(netD.state_dict(), best_model_d)\n","\n","# Generamos y guardamos gráfica evolución de errores\n","plt.figure(figsize=(10, 5))\n","plt.plot(range(EPOCH), losses_D, label='Perdida Discriminador', color='red')\n","plt.plot(range(EPOCH), losses_G, label='Perdida Generador', color='blue')\n","plt.xlabel('Época')\n","plt.ylabel('Perdida')\n","plt.title('Perdida del Generador y Discriminador por Época')\n","plt.legend()\n","plt.grid(True)\n","plt.savefig(os.path.join(BASE_SAVE_PATH, 'loss_plot.png')) # Guarda la gráfica\n","plt.show()\n","\n","# Generamos lote de imágenes falsas\n","\n","if not os.path.exists(TEST_SAVE_PATH):\n","    os.makedirs(TEST_SAVE_PATH)\n","    print(f\"Carpeta de imágenes generadas creada en: {TEST_SAVE_PATH}\")\n","\n","im_batch_size = 50\n","n_images=10\n","\n","for i_batch in tqdm(range(0, n_images, im_batch_size)):\n","    gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n","    gen_images = netG(gen_z)\n","    images = gen_images.to(\"cpu\").clone().detach()\n","with torch.no_grad():\n","    outputs = netD(gen_images)\n","    images = images.numpy().transpose(0, 2, 3, 1)\n","    for i_image in range(gen_images.size(0)):\n","        save_image(gen_images[i_image, :, :, :], os.path.join(TEST_SAVE_PATH, f'image_{i_batch+i_image:05d}.png'))\n","\n","for i_image in range(gen_images.size(0)):\n","        score = outputs[i_image].item()\n","        print(f'Imagen {i_batch + i_image:05d} - Discriminador: {score:.4f}')\n","        save_image(gen_images[i_image, :, :, :], os.path.join(TEST_SAVE_PATH, f'image_{i_batch+i_image:05d}.png'))\n","\n","fig = plt.figure(figsize=(25, 16))\n","\n","# mostramos 10 imagenes falsas por clase\n","for i, j in enumerate(images[:32]):\n","    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n","    plt.imshow(j)"],"metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-10T10:42:55.503033Z","iopub.execute_input":"2025-06-10T10:42:55.503343Z"},"trusted":true,"id":"dHlOOHNS-6hs"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# ENTRENADOR 2 ( 2 optimizaciones de generador por cada una del discriminador, vectores ruido nuevos)\n","\n","# Descomentar el data loader seleccionado:\n","# data_loader = train_loader\n","data_loader = train_loader_noresize\n","\n","EPOCH = 600 # número de épocas\n","\n","losses_D = []\n","losses_G = []\n","\n","t0 = time()\n","for epoch in range(EPOCH):\n","    epoch_loss_D = 0\n","    epoch_loss_G = 0\n","    num_batches = 0\n","    for i, data in enumerate(data_loader, 0):\n","\n","        #Actualizamos pesos de la red del Discrimnador\n","        netD.zero_grad()\n","\n","        # Entrenamos Discriminador con imágenes reales del dataset\n","        input,_ = data\n","        input = input.to(device)\n","        target = torch.ones(input.size()[0]).to(device)\n","        output = netD(input)\n","        errD_real = criterion(output, target)\n","\n","        # Entrenamos el Discriminador con imágenes falsas producidas por el Generador\n","        noise = torch.randn(input.size()[0], 100, 1, 1).to(device)\n","        fake = netG(noise)\n","        target = torch.zeros(input.size()[0]).to(device)\n","        output = netD(fake.detach())\n","        errD_fake = criterion(output, target)\n","\n","        # Calculamos error total del Discriminador y hacemos backpropagation\n","        errD = errD_real + errD_fake\n","        errD.backward()\n","        optimizerD.step()\n","\n","        # Hacemos primera actualización de pesos del Generador\n","        # con nuevo oote de imágenes sintéticas\n","        noise = torch.randn(input.size()[0], 100, 1, 1).to(device)\n","        fake = netG(noise)\n","        netG.zero_grad()\n","        target = torch.ones(input.size()[0]).to(device)\n","        output = netD(fake)\n","        errG = criterion(output, target)\n","        errG.backward()\n","        optimizerG.step()\n","\n","        # Hacemos segunda actualización de pesos del Generador con nuevo lote de imágenes sintéticas\n","        noise = torch.randn(input.size()[0], 100, 1, 1).to(device)\n","        fake = netG(noise)\n","        netG.zero_grad()\n","        target = torch.ones(input.size()[0]).to(device)\n","        output = netD(fake)\n","        errG = criterion(output, target)\n","        errG.backward()\n","        optimizerG.step()\n","\n","        # Acumulamos errores y número de lotes por época\n","        epoch_loss_D += errD.item()\n","        epoch_loss_G += errG.item()\n","        num_batches += 1\n","\n","    losses_D.append(epoch_loss_D / num_batches)\n","    losses_G.append(epoch_loss_G / num_batches)\n","\n","    # 3rd Step: Printing the losses and saving the real images and the generated images of the last minibatch\n","    # Mostramos los errores del G y D en la época y generamos una muestra de imágenes\n","    print('[%d/%d] Loss_D: %.4f; Loss_G: %.4f' % (epoch, EPOCH, errD.item(), errG.item()))\n","    save_image(input, os.path.join(BASE_SAVE_PATH, 'real_samples.png'), normalize=True)\n","    save_image(fake.data, os.path.join(BASE_SAVE_PATH, 'fake_samples_epoch_%03d.png' % epoch), normalize=True)\n","\n","tf = time()\n","print(tf - t0)\n","\n","# Salvamos pesos de Generador y Discriminador\n","best_model_g = os.path.join(BASE_SAVE_PATH, 'generator_v2.pth')\n","best_model_d = os.path.join(BASE_SAVE_PATH, 'discriminator_v2.pth')\n","torch.save(netG.state_dict(), best_model_g)\n","torch.save(netD.state_dict(), best_model_d)\n","\n","# generamos y guardamos gráfica de errores\n","plt.figure(figsize=(10, 5))\n","plt.plot(range(EPOCH), losses_D, label='Pérdida Discriminador', color='red')\n","plt.plot(range(EPOCH), losses_G, label='Pérdida Generador', color='blue')\n","plt.xlabel('Época')\n","plt.ylabel('Pérdida')\n","plt.title('Pérdida del Generador y Discriminador por Época')\n","plt.legend()\n","plt.grid(True)\n","plt.savefig(os.path.join(BASE_SAVE_PATH, 'loss_plot.png')) # Guarda la gráfica\n","plt.show()\n","\n","# Generamos lote de imágenes de muestra\n","\n","if not os.path.exists(TEST_SAVE_PATH):\n","    os.makedirs(TEST_SAVE_PATH)\n","    print(f\"Carpeta de imágenes generadas creada en: {TEST_SAVE_PATH}\")\n","\n","im_batch_size = 50\n","n_images=10\n","\n","for i_batch in tqdm(range(0, n_images, im_batch_size)):\n","    gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n","    gen_images = netG(gen_z)\n","    images = gen_images.to(\"cpu\").clone().detach()\n","with torch.no_grad():\n","    outputs = netD(gen_images)\n","    images = images.numpy().transpose(0, 2, 3, 1)\n","    for i_image in range(gen_images.size(0)):\n","        save_image(gen_images[i_image, :, :, :], os.path.join(TEST_SAVE_PATH, f'image_{i_batch+i_image:05d}.png'))\n","\n","for i_image in range(gen_images.size(0)):\n","        score = outputs[i_image].item()\n","        print(f'Imagen {i_batch + i_image:05d} - Discriminador: {score:.4f}')\n","        save_image(gen_images[i_image, :, :, :], os.path.join(TEST_SAVE_PATH, f'image_{i_batch+i_image:05d}.png'))\n","\n","fig = plt.figure(figsize=(25, 16))\n","\n","# Mostramos 10 imágenes de cada clase\n","\n","for i, j in enumerate(images[:32]):\n","    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n","    plt.imshow(j)"],"metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2025-06-10T10:42:55.503033Z","iopub.execute_input":"2025-06-10T10:42:55.503343Z"},"trusted":true,"id":"TSzY1rxJZ2kw"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# OPERACIONES SEPARADAS"],"metadata":{"id":"Hhe4utAVBMIT"}},{"cell_type":"markdown","source":["# Guardar pesos"],"metadata":{"id":"M7Y4jd7d-6hs"}},{"cell_type":"code","source":["# Guardamos pesos ajustados\n","best_model_g = os.path.join(BASE_SAVE_PATH, 'generator_v1.pth') # Puedes usar el mismo BASE_SAVE_PATH\n","best_model_d = os.path.join(BASE_SAVE_PATH, 'discriminator_v1.pth') # Puedes usar el mismo BASE_SAVE_PATH\n","torch.save(netG.state_dict(), best_model_g)\n","torch.save(netD.state_dict(), best_model_d)"],"metadata":{"trusted":true,"id":"vbP5cC7B-6ht"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Recuperar pesos"],"metadata":{"id":"w3JbGK4X-6ht"}},{"cell_type":"code","source":["# Cagarmos pesos desde modelo entrenado y guardado\n","RECOVER_PATH = '/content/drive/MyDrive/ColabNotebooks/ALMACEN/entrenamiento42/' # ruta donde se guardó\n","best_model_g = os.path.join(RECOVER_PATH, 'generator_42.pth') # nombre del archivo de pesos del generador\n","best_model_d = os.path.join(RECOVER_PATH, 'discriminator_42.pth') # nombre del archivo de pesos del discriminador\n","\n","if os.path.exists(best_model_g) and os.path.exists(best_model_d):\n","    netG.load_state_dict(torch.load(best_model_g, map_location=device)) # Añadir map_location=device si es necesario\n","    netD.load_state_dict(torch.load(best_model_d, map_location=device)) # Añadir map_location=device si es necesario\n","    print(\"Modelos cargados exitosamente desde Drive.\")\n","\n","# netG.load_state_dict(torch.load(best_model_g, weights_only=True))\n","# netD.load_state_dict(torch.load(best_model_d, weights_only=True))"],"metadata":{"trusted":true,"id":"hM9MXpFQ-6ht"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Gráfica de errores\n"],"metadata":{"id":"CB_YRj1M-6ht"}},{"cell_type":"code","source":["def plot_loss (G_losses, D_losses, epoch):\n","    plt.figure(figsize=(10,5))\n","    plt.title(\"Generator and Discriminator Loss - EPOCH \"+ str(epoch))\n","    plt.plot(G_losses,label=\"G\")\n","    plt.plot(D_losses,label=\"D\")\n","    plt.xlabel(\"iterations\")\n","    plt.ylabel(\"Loss\")\n","    plt.legend()\n","    plt.show()"],"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true,"id":"ZBH15s02-6ht"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Mostrar imágenes generadas\n"],"metadata":{"id":"xw3_99l9-6hu"}},{"cell_type":"code","source":["def show_generated_img(n_images=5):\n","    sample = []\n","    for _ in range(n_images):\n","        noise = torch.randn(1, nz, 1, 1, device=device)\n","        gen_image = netG(noise).to(\"cpu\").clone().detach().squeeze(0)\n","        gen_image = gen_image.numpy().transpose(1, 2, 0)\n","        sample.append(gen_image)\n","\n","    figure, axes = plt.subplots(1, len(sample), figsize = (64,64))\n","    for index, axis in enumerate(axes):\n","        axis.axis('off')\n","        image_array = sample[index]\n","        axis.imshow(image_array)\n","\n","    plt.show()\n","    plt.close()"],"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"trusted":true,"id":"47hfx1xj-6hu"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["nz=100\n","show_generated_img()"],"metadata":{"trusted":true,"id":"PQfCKXU--6hv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(range(EPOCH), losses_D, label='Perdida Discriminador', color='red')\n","plt.plot(range(EPOCH), losses_G, label='Perdida Generador', color='blue')\n","plt.xlabel('Época')\n","plt.ylabel('Perdida')\n","plt.title('Perdida del Generador y Discriminador por Época')\n","plt.legend()\n","plt.grid(True)\n","plt.savefig(os.path.join(BASE_SAVE_PATH, 'loss_plot.png'))  # Guarda la gráfica\n","plt.show()"],"metadata":{"trusted":true,"id":"kesfC8N2-6hv"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Generación de ejemplos"],"metadata":{"id":"wJsLEmM7-6hw"}},{"cell_type":"code","source":["if not os.path.exists('./test'):\n","    os.mkdir('./test')\n","\n","im_batch_size = 50\n","n_images=10\n","\n","for i_batch in tqdm(range(0, n_images, im_batch_size)):\n","    gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n","    gen_images = netG(gen_z)\n","    images = gen_images.to(\"cpu\").clone().detach()\n","with torch.no_grad():\n","    outputs = netD(gen_images)\n","    images = images.numpy().transpose(0, 2, 3, 1)\n","    for i_image in range(gen_images.size(0)):\n","        save_image(gen_images[i_image, :, :, :], os.path.join('./test', f'image_{i_batch+i_image:05d}.png'))\n"],"metadata":{"trusted":true,"id":"y2Ec3pwz-6hw"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["    for i_image in range(gen_images.size(0)):\n","        score = outputs[i_image].item()\n","        print(f'Imagen {i_batch + i_image:05d} - Discriminador: {score:.4f}')\n","        save_image(gen_images[i_image, :, :, :], os.path.join('./test', f'image_{i_batch+i_image:05d}.png'))\n"],"metadata":{"trusted":true,"id":"B-INo67z-6hx"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["fig = plt.figure(figsize=(25, 16))\n","# Mostrar 10 imágenes de cada clase\n","for i, j in enumerate(images[:32]):\n","    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n","    plt.imshow(j)"],"metadata":{"_kg_hide-input":true,"trusted":true,"id":"QQqUhLfo-6hy"},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Generar lote de imágenes (código agrupado)\n","\n","if not os.path.exists(TEST_SAVE_PATH):\n","    os.makedirs(TEST_SAVE_PATH)\n","    print(f\"Carpeta de imágenes generadas creada en: {TEST_SAVE_PATH}\")\n","\n","im_batch_size = 50\n","n_images=10\n","\n","for i_batch in tqdm(range(0, n_images, im_batch_size)):\n","    gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n","    gen_images = netG(gen_z)\n","    images = gen_images.to(\"cpu\").clone().detach()\n","with torch.no_grad():\n","    outputs = netD(gen_images)\n","    images = images.numpy().transpose(0, 2, 3, 1)\n","    for i_image in range(gen_images.size(0)):\n","        save_image(gen_images[i_image, :, :, :], os.path.join(TEST_SAVE_PATH, f'image_{i_batch+i_image:05d}.png'))\n","\n","for i_image in range(gen_images.size(0)):\n","        score = outputs[i_image].item()\n","        print(f'Imagen {i_batch + i_image:05d} - Discriminador: {score:.4f}')\n","        save_image(gen_images[i_image, :, :, :], os.path.join(TEST_SAVE_PATH, f'image_{i_batch+i_image:05d}.png'))\n","\n","fig = plt.figure(figsize=(25, 16))\n","\n","# display 10 images from each class\n","for i, j in enumerate(images[:32]):\n","    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n","    plt.imshow(j)"],"metadata":{"id":"T9lHhoe0FjC1"},"execution_count":null,"outputs":[]}]}